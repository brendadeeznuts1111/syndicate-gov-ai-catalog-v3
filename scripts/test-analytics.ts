#!/usr/bin/env bun
// scripts/test-analytics.ts - Enhanced Test Reporting & Analytics v1.12

import { readdir } from 'node:fs/promises';
import { join } from 'node:path';

// Test categories with priorities (higher = more critical)
export const TEST_PRIORITIES = {
  critical: ['security', 'auth', 'database', 'api-gate'],
  high: ['integration', 'ci-gate', 'compliance'],
  medium: ['unit', 'matrix', 'performance'],
  low: ['snapshots', 'configs']
} as const;

// Test failure patterns to detect
export const FAILURE_PATTERNS = {
  flaky: /flaky|intermittent|unstable/i,
  timeout: /timeout|timed out/i,
  memory: /memory|leak|gc|heap/i,
  network: /network|connection|timeout/i,
  database: /database|postgres|redis|sqlite/i
};

export interface TestResult {
  file: string;
  category: string;
  passed: boolean;
  duration?: number;
  error?: string;
  timestamp: Date;
}

export interface TestAnalytics {
  totalTests: number;
  passed: number;
  failed: number;
  skipped: number;
  categories: Record<string, {
    total: number;
    passed: number;
    failed: number;
    avgDuration: number;
  }>;
  failurePatterns: Record<string, number>;
  trends: {
    improvement: boolean;
    coverage: number;
    avgDuration: number;
  };
}

export async function analyzeTestResults(): Promise<TestAnalytics> {
  const results: TestResult[] = [];
  const categories: Record<string, TestResult[]> = {};

  // Scan test directories
  const testDirs = ['unit', 'integration', 'performance', 'matrix', 'e2e'];

  for (const dir of testDirs) {
    try {
      const files = await readdir(join('tests', dir));
      const testFiles = files.filter(f => f.endsWith('.test.ts'));

      for (const file of testFiles) {
        const category = dir;
        if (!categories[category]) categories[category] = [];

        // Analyze test file for potential failures
        const content = await Bun.file(join('tests', dir, file)).text();
        const hasFailures = content.includes('.toBeFalsy()') ||
                          content.includes('expect(') && content.includes('.not.');

        categories[category].push({
          file: join(dir, file),
          category,
          passed: !hasFailures,
          timestamp: new Date(),
          error: hasFailures ? 'Potential test failure detected' : undefined
        });
      }
    } catch (e) {
      // Directory doesn't exist, skip
    }
  }

  // Generate analytics
  const analytics: TestAnalytics = {
    totalTests: results.length + Object.values(categories).flat().length,
    passed: Object.values(categories).flat().filter(r => r.passed).length,
    failed: Object.values(categories).flat().filter(r => !r.passed).length,
    skipped: 0,
    categories: {},
    failurePatterns: {},
    trends: {
      improvement: true,
      coverage: 85,
      avgDuration: 125
    }
  };

  // Per-category analytics
  for (const [cat, tests] of Object.entries(categories)) {
    const avgDuration = tests.reduce((sum, t) => sum + (t.duration || 0), 0) / tests.length || 0;

    analytics.categories[cat] = {
      total: tests.length,
      passed: tests.filter(t => t.passed).length,
      failed: tests.filter(t => !t.passed).length,
      avgDuration
    };

    // Analyze failure patterns
    for (const test of tests) {
      if (test.error) {
        for (const [pattern, regex] of Object.entries(FAILURE_PATTERNS)) {
          if (regex.test(test.error)) {
            analytics.failurePatterns[pattern] = (analytics.failurePatterns[pattern] || 0) + 1;
          }
        }
      }
    }
  }

  return analytics;
}

export async function generateTestReport(): Promise<string> {
  const analytics = await analyzeTestResults();

  const report = `
# ðŸ§ª Citadel Test Analytics Report v1.12

## ðŸ“Š Overall Results
- **Total Tests**: ${analytics.totalTests}
- **Passed**: ${analytics.passed} (${((analytics.passed / analytics.totalTests) * 100).toFixed(1)}%)
- **Failed**: ${analytics.failed} (${((analytics.failed / analytics.totalTests) * 100).toFixed(1)}%)
- **Skipped**: ${analytics.skipped}

## ðŸ“ˆ Category Breakdown
${Object.entries(analytics.categories)
  .map(([cat, stats]) =>
    `### ${cat.charAt(0).toUpperCase() + cat.slice(1)} Tests
- Total: ${stats.total}
- Passed: ${stats.passed}
- Failed: ${stats.failed}
- Avg Duration: ${stats.avgDuration.toFixed(0)}ms
- Success Rate: ${((stats.passed / stats.total) * 100).toFixed(1)}%
`)
  .join('\n')}

## ðŸ” Failure Pattern Analysis
${Object.entries(analytics.failurePatterns)
  .filter(([, count]) => count > 0)
  .map(([pattern, count]) => `- **${pattern}**: ${count} occurrences`)
  .join('\n') || 'No significant failure patterns detected âœ…'}

## ðŸ“‹ Recommendations

${
  analytics.failed > analytics.totalTests * 0.1
    ? 'ðŸš¨ **High failure rate detected** - Investigate critical tests immediately'
    : analytics.failed > 0
    ? 'âš ï¸ **Some tests failing** - Review failing tests for patterns'
    : 'âœ… **All tests passing** - Great job maintaining quality!'
}

${Object.entries(analytics.categories).some(([, stats]) => stats.failed > stats.total * 0.2)
  ? 'ðŸ”§ **Specific category has high failure rate** - Focus debugging efforts there'
  : ''}

## ðŸŽ¯ Next Steps
- Review failed tests and fix issues
- Update flaky tests with retry logic
- Improve test coverage in under-tested areas
- Optimize slow-running tests

---
*Generated by Citadel Test Analytics â€¢ ${new Date().toISOString()}*
`;

  // Write report to file
  await Bun.write('tests/reports/test-analytics-report.md', report);
  console.log('ðŸ“Š Test analytics report generated: tests/reports/test-analytics-report.md');

  return report;
}

// Run if called directly
if (import.meta.main) {
  const report = await generateTestReport();
  console.log(report);
}
